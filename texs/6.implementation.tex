\section{Implementation}~\label{sec:implementation}

We implement our technique in a tool \tool (a fork of \cadical
%  commit f13d74439a5b5c963ac5b02d05ce93a8098018b8
) as a preprocessing step. By default, \tool will run the preprocessing step for
30 seconds. After this time, it will exit and commence normal solving,
regardless of whether it has found any \pr clauses. This implementation adds ??
lines of C++ code to \cadical and we believe it is implementable within any CDCL
SAT solver. We experimented with other heuristics, which we briefly describe. We
include an evaluation of the heuristics in \autoref{subsec:heuristics}.

% \subsection{Other Heuristics}~\label{subsec:heuristics}

% todo: maybe move these two paragraphs to implementation section

% \noindent \textbf{Sorting $\alpha_a$ by Implication:}%~\label{subsubsec:impordering}
% The greedy set cover algorithm described above is almost sufficient for being insensitive to heuristics, but there is one other optimization that we made. \autoref{alg:finda0} describes sorting $\alpha_a$ as an initial step. This is important for cases where there are more than one cover of the same size. The most common occurence of this is for $a_1, a_2 \in \alpha_a$, we may have that $\overline{a_2} \impunit^\phi \overline{a_1} \impunit^\phi c_1, ..., c_n$. 

% Thus, greedy set cover could pick $\{a_1\}$ or $\{a_2\}$ as singleton sets. However, since $a_1 \impunit^\phi a_2$, we really want to learn the unit clause $a_1$ since it is much more powerful.

\subsubsection{Sorting $\alpha_a$ by Implication}~\label{subsubsec:impordering}
The greedy set cover algorithm described above is almost sufficient for being
insensitive to heuristics, but there is one other optimization that we made.
\autoref{alg:finda0} describes sorting $\alpha_a$ as an initial step. This is
important for cases where there are more than one cover of the same size. The
most common occurence of this is for $a_1, a_2 \in \alpha_a$, we may have that
$\overline{a_2} \impunit^\phi \overline{a_1} \impunit^\phi c_1, ..., c_n$. 


\subsubsection{Filtering Trivial Clauses}~\label{subsubsec:filteringtriv}
Introducing globally blocked clauses can affect how we divide $\alpha = \alpha_c
\sqcup \alpha_a$ as done in \autoref{alg:leastcond}. Thus, it is better to avoid
introducing globally blocked clauses if they are not useful. We do this by
checking if $\phi \impunit C$ for each potential clause $C$. If it is implied by
unit propagation, we do not learn it since we consider it easy to learn.

\subsubsection{Filtering based on Clause Length}~\label{subsubsec:filtering-length}
Another heuristic for filtering is based on clause size. If a clause is longer
than some size $k$ we may choose not to learn it as shorter clauses are
typically more useful. This can be combined with filtering out trivial clauses
or used separately.

\subsubsection{Ordering Literals}~\label{subsubsec:ordering-literals}
So far, we are considering literals $i$ and $j$ to propagate on randomly.
However, there could be better ways to order literals. One techinque is to order
$i$ based on the number of clauses it occurs in. Another is, once an $i$ is
chosen, we pick $j$ based on if it touches $i$, i.e. if $j$ occurs in the same
clause as $i$ or a variable propagate by $i$. This was originally proposed in
Reeves et al ~\cite{prelearn}.

\subsubsection{Alternative Shrinking techniques}~\label{subsubsec:shrink-techniques}
We discussed in \autoref{subsec:shrink} that we can shrink a checking if $\phi
\impunit a \lor c$, where $a \in \alpha_a$ and $c \in \alpha_c$. While, this is
not the most expensive check, it can be made cheaper. Essentially, we just check
if there is a clause $a \lor c$ in the original formula. While, there may be
pairs $a \lor c$ that were missed, this is fast and good enough for certain
benchmarks such as the pigeonhole principle. Another alternative is to not
shrink the clause at all.

% Here is a complete list of flags discussed in 
