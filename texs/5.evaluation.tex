\section{Evaluation}~\label{sec:evaluation}

In this section, we empirically evaluate our technique against other \pr clause
learning techniques. In doing so, we aim to answer the following research
questions:


\begin{enumerate}
    \item Can our approach provide short \pr proofs for certain benchmark
    families?
    \item Is our approach less sensitive to encoding choices compared to other
    \pr learning techniques?
    % \item Can these techniques underperform or outperform SAT solvers on other
    % certain benchmark families?
\end{enumerate}


We compare the two main tools learning \pr clauses: \sadical (based on SDCL) and
\prelearn (a preprocessing technique that calls \sadical). To be consistent with
our approach, we run \prelearn with 50 iterations and for 30 seconds. We also
compare to \cadical as a baseline with no \pr clause learning.

All experiments were performed in the Anvil Supercomputing Center on nodes with
128 cores and 2 GB RAM per core~\cite{anvil}. We ran 64 experiments in parallel
per node with a 5,000 second timeout, the default timeout for the SAT
competition.

In \autoref{subsec:eval-pigeonhole}, we compare all approaches on the pigeonhole
principle, evaluating runtime, proof length, and sensitivity to the encoding of
the formula. In \autoref{subsec:eval-satcomp}, we evaluate the solvers on
benchmarks from the '22, '23, and '24 SAT competition's main
tracks~\cite{satcomp2022,satcomp2023,satcomp2024}. In
\autoref{subsec:eval-discussion}, we highlight certain benchmark families that
benefit from \pr clause learning.
%We evaluate the different approaches on these families. 
Finally, we analyze the use of specific heuristic choices in \tool by turning
heuristics off individually and observing their effect
(\autoref{subsec:eval-heuristics}). 



\subsection{Pigeonhole results}~\label{subsec:eval-pigeonhole}

\begin{figure*}[!t]
    \centering
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/pigeonhole_runtime_comparison.jpg}
        % \caption{Runtime on Pigeonhole Principle formulae}
        \label{fig:pigeonhole-runtime-comparison}
    \end{subfigure}
    \hspace{0.06\textwidth}
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/pigeonhole_proof_size_comparison.jpg}
        % \caption{Proof Size for Pigeonhole Principle formulae}
        \label{fig:pigeonhole-proof-size-comparison}
    \end{subfigure}
    \caption{Comparison of \tool, \cadical, \sadical, and \prelearn on pigeonhole principle benchmarks up to size $40$. The y-axis is on a cube root scale. The performance of a solver on the original benchmark is shown with a solid line. The median of 5 scranfilized queries is shown with a dashed line. If a solver times out on a query in 5000s, it is not shown.}
    \label{fig:pigeonhole-results}
\end{figure*}


Approaches based on SDCL, such as \sadical, are successful for learning $O(n^3)$
proofs for the pigeonhole principle, but are very sensitive to the encoding of
the formula. We compare the solvers on pigeonhole principle from \ph{2} to
\ph{40} and plot these results in \autoref{fig:pigeonhole-results}. As the
expected best-behavior is cubic, we use a cube root scale for the y-axis.

As expected, \cadical grows exponentially, while \sadical and \tool scale
cubicly in both runtime and proof size. Significantly, \tool is able to learn
$3.59$-$3.64\times$ shorter proofs compared to \sadical. 
% on formulae larger than \ph{10}
% This is because \sadical deletes clauses more frequently.
% , as to not exclude
% other clauses from being learned. Frequent deletion is not necessary in \tool
% because of its clause shrinking technique. 
\prelearn scales cubicly on small formulae, but for \ph{22} and larger, will not
learn enough useful \pr clauses in the preprocessing step and will timeout after
spending the rest of its time running \cadical.

% As we discuss in \autoref{app:pigeonhole}, \tool learns proofs of size
% $\approx \frac13 n^3$, which is expected to be shorter than known \pr proofs
% for the pigeonhole principle.

Additionally, we evaluate all solvers on scranfilized variations of the
pigeonhole principle. Scranfilization is a technique for generating an
satisfiability-equivalent formula~\cite{scranfilize}. We use the tool
\texttt{scranfilize}~\cite{scranfilize} with the options permuting variables,
permuting clauses, and flipping literals (with probability $0.5$) all turned on.
We run each solver on 5 scranfilized variations for each benchmark and take the
median runtime and proof size. This is shown in \autoref{fig:pigeonhole-results}
with dashed lines.

\sadical and \prelearn exhibit an exponential trend for runtime and proof size
on the scranfilized benchmarks. \sadical will spend all its time in the main
SDCL loop not learning enough useful clauses. \prelearn will learn some useful
\pr clauses in preprocessing, but not enough to sufficiently shrink the search
space for formulae larger than \ph{16}.

On the other hand, \tool almost matches its non-scranfilized performance,
demonstrating that it learns useful \pr clauses regardless of the encoding.

% In conclusion, \tool is able to match \sadical's runtime for the pigeonhole
% principle while shorter proofs by a constant factor. Additionally, \tool is
% insensitive to permuting variables, permuting clauses, and flipping literals
% as it relies on conditional autarkies, a global property of the formula.



\subsection{SAT competition results}~\label{subsec:eval-satcomp}


\begin{table}[ht]
    \centering
    \sisetup{table-format=3}        % remove if you are not using siunitx
    \begin{tabular}{lrrrrr}
      \toprule
      & \multicolumn{2}{c}{0--10k} & \multicolumn{2}{c}{10k--20M} \\
      \cmidrule(lr){2-3} \cmidrule(lr){4-5} & SAT & UNSAT & SAT & UNSAT & Total
      \\
      \midrule
    %   Total Formulas & 70 & 132 & 395 & 416 & 1099 \\
      \cadical Solved  &  54 &  73 & 319 & 303 & 749 \\
      \midrule
      \prelearn \\
      \; Total &  52 &  90 & 322 & 307 & 771 \\
      \; Learnt clauses   &  40 &  73 & 179 & 145 & 431\\
      \; Learnt $>50$ clauses   &  22 &  51 & 104 &  79 & 256\\
      \; Improved &  11 &  42 &  57 &  36 & 146\\
      \; Exclusively &   1 &  17 &   6 &   6 & 30 \\
      \midrule
      \tool \\
      \; Total &  52 &  87 & 317 & 298 & 754 \\
      \; Learnt clauses     &   16 &  58 &  30 &  35 & 139 \\
      \; Learnt $>50$ clauses  &   1  &  39 &  6 &  11 & 57 \\
      \; Improved &  23  &  48 &  89 &  59 & 219 \\
      \; Exclusively &   0 &  18 &   9 &   9 & 36 \\
      \bottomrule
    \end{tabular}
    \caption{Number of solved instances.}
    \label{tab:solver-stats}
  \end{table}


%   Category                                        0-10k SAT  0-10k UNSAT  10k-20M SAT  10k-20M UNSAT  20M+ SAT  20M+ UNSAT  Total
% Total Formulas                                         70          132          395            416        40          46   1099
% Cadical Solved                                         54           73          319            303        35          46    830
% Has PR Clauses                                         57           90          224            220         0           3    594
% Has Many PR Clauses                                    36           66          131            137         0           0    370
% Prelearn Solved                                        52           90          322            307        35          46    852
% Prelearn Only                                           1           17            6              6         0           0     30
% Prelearn Only (on formulas we learn stuff)              1           17            6              5         0           0     29
% Prelearn Improved                                      11           42           57             36         1           1    148
% Prelearn Improved (on formulas we learn stuff)          9           41           51             27         0           0    128
% Cautical Solved                                        52           87          317            298        32          29    815
% Cautical Only                                           0           18            9              9         0           0     36
% Cautical Only (on formulas we learn stuff)              0           18            1              4         0           0     23
% Cautical Improved                                      23           48           89             59         0           8    227
% Cautical Improved (on formulas we learn stuff)          7           38            4              7         0           0     56
% Blocked Clauses                                        16           61           36             74         0           0    187
% Has Many Blocked Clauses                                1           42            7             45         0           0     95

%   Category                                          0-10k SAT  0-10k UNSAT  10k-20M SAT  10k-20M UNSAT        Total
% Total Formulas                                    70.000000   132.000000   395.000000     416.000000  1013.000000
% Cadical Solved                                    54.000000    73.000000   319.000000     303.000000   749.000000
% Has PR Clauses                                    57.000000    90.000000   224.000000     220.000000   591.000000
% Has Many PR Clauses                               36.000000    66.000000   131.000000     137.000000   370.000000
% Prelearn Solved                                   52.000000    90.000000   322.000000     307.000000   771.000000
% Prelearn Only                                      1.000000    17.000000     6.000000       6.000000    30.000000
% Prelearn Only (on formulas we learn stuff)         1.000000    17.000000     6.000000       5.000000    29.000000
% Prelearn Only % (on formulas we learn stuff)       0.017544     0.188889     0.026786       0.022727     0.255946
% Prelearn Improved                                 11.000000    42.000000    57.000000      36.000000   146.000000
% Prelearn Improved (on formulas we learn stuff)     9.000000    41.000000    51.000000      27.000000   128.000000
% Prelearn Improved % (on formulas we learn stuff)   0.157895     0.455556     0.227679       0.122727     0.963856
% Cautical Solved                                   52.000000    87.000000   317.000000     298.000000   754.000000
% Cautical Only                                      0.000000    18.000000     9.000000       9.000000    36.000000
% Cautical Only (on formulas we learn stuff)         0.000000    18.000000     1.000000       4.000000    23.000000
% Cautical Only % (on formulas we learn stuff)       0.000000     0.295082     0.027778       0.054054     0.376914
% Cautical Improved                                 23.000000    48.000000    89.000000      59.000000   219.000000
% Cautical Improved (on formulas we learn stuff)     7.000000    38.000000     4.000000       7.000000    56.000000
% Cautical Improved % (on formulas we learn stuff)   0.437500     0.622951     0.111111       0.094595     1.266157
% Blocked Clauses                                   16.000000    61.000000    36.000000      74.000000   187.000000
% Has Many Blocked Clauses                           1.000000    42.000000     7.000000      45.000000    95.000000

  % Category                  0-10k SAT  0-10k UNSAT  10k-20M SAT  10k-20M UNSAT
  % 20M+ SAT  20M+ UNSAT  Total
% Total Formulas                   70          132          395            416
% 40          46   1099 -> issue with this total is that certain formula
% statuses are unknown, so not counted here Cadical Solved                   54
% 73          319            303        35          46    830 Has PR Clauses
% 40           73          179            145         0           3    440 Has
% Many PR Clauses              22           51          104             79
% 0           0    256 Prelearn Solved                  52           90
% 322            307        35          46    852 Prelearn Only
% 1           17            6              6         0           0     30
% Prelearn Improved                11           42           57             36
% 1           1    148 Cautical Solved                  52           87
% 317            298        32          29    815 Cautical Only
% 0           18            9              9         0           0     36
% Cautical Improved                23           48           89             59
% 0           8    227 Blocked Clauses                  16           58
% 30             35         0           0    139 Has Many Blocked Clauses
% 1           39            6             11         0           0     57




\begin{figure*}[!t]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/cadical_vs_cautical_nontrivial.jpg}
        \caption{Comparing \tool to \cadical. The color indicates the number of \pr clauses learnt by \tool}
        \label{fig:cautical-vs-cadical}
    \end{subfigure}
    \hspace{0.06\textwidth}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/cadical_vs_prelearn_nontrivial.jpg}
        \caption{Comparing \prelearn to \cadical. The color indicates the number of \pr clauses learnt by \prelearn}
        \label{fig:cautical-vs-prelearn}
    \end{subfigure}
    \caption{Performance comparison of \tool with and \prelearn with \cadical on SAT competition benchmarks. We filter out all benchmarks where the solvers do not learn any \pr clauses. The color indicates the number of \pr clauses learnt by the solver.}
    \label{fig:solver-comparison}
\end{figure*}

We compare the performance of \tool with \cadical and \prelearn on the
benchmarks from the '22, '23, and '24 SAT competition's main
tracks~\cite{satcomp2022,satcomp2023,satcomp2024}. We remove duplicates and
exclude all benchmarks with more than twenty million clauses as our technique
is not designed to handle such large formulas and will oftentimes memout. This gives us a
total of 1089 benchmarks. We excluded \sadical from our evaluation as it 
only solves 22 of these benchmarks.

\autoref{tab:solver-stats} shows the number of instances solved by each solver
and the number of queries for which \prelearn and \cadical learn additional \pr
clauses, how many improve upon \cadical by at least 5\%, and how many solve a
formula that \cadical does not solve. We divide the benchmarks based on number
of clauses (0-10k or 10k-20M) and status (SAT or UNSAT). 

The number of clauses 
is a good indicator of the type of benchmark, formulas with less that ten thousand
clauses are mostly combinatorial problems, while formulas with more than ten thousand
clauses are mostly industrial. Whether a formula is SAT or UNSAT is a good indicator 
of how helpful \pr clauses are. SAT formulas are sensitive to search heuristics, so 
adding a \pr clause can have a significant (positive or negative) effect on performance
regardless of whether the clause is actually useful.

PAR-2 score is a standard metric used to evaluate the performance of solvers. It
is evaluated as the sum of the runtimes of solved instances and twice the
timeout of unsolved instances. On this dataset, \cadical has a PAR2-score of
3521.79 seconds, \prelearn has a PAR2-score of 3331.41 seconds, and \tool has a
PAR2-score of 3442.14 seconds. This can be explained by \prelearn solving the
most formulae at 771, followed by \tool at 754, and \cadical at 749.

%  I don't know if this actually makes sense
Notably, \tool solves 36 formulae that \cadical does not solve, while \prelearn
solves 30 that \cadical does not solve. \tool improves on 219 formulae from
\cadical, while \prelearn improves on 146 formulae. We attribute this to more
selective \pr clause learning techniques in \tool. Learning unhelpful \pr
clauses can have a detrimental effect on performance. \tool only learns 50 \pr
clauses or more for 57 formulae, while \prelearn learns 50 \pr clauses or more
for 256 formulae. On those clauses, \tool improves the \cadical's runtime on
29.9\% of benchmarks, while \prelearn improves it by 24.7\% of benchmarks.
% todo: double check these numbers and table
% todo: maybe add numbers for formula where we learn 50 clauses or more

\autoref{fig:solver-comparison} shows \tool and \cadical's performance relative
to \cadical. We only include points where \tool (for
\autoref{subfig:cautical-vs-cadical}) and \prelearn (for
\autoref{subfig:cautical-vs-prelearn}) learn at least one \pr clause.
\autoref{subfig:cautical-vs-cadical} shows that \tool learns a large number of
\pr clauses for formulae that it can solve quickly and \cadical times out on.
\autoref{subfig:cautical-vs-prelearn} shows that \prelearn also solve a number
of formulae that \tool cannot, but it learns a large number of \pr clauses for
other formulae.







% prelearn PAR score:  3331.406813590451 cautical PAR score:  3442.137998163452
% cadical PAR score:  3521.7908356290172




  \begin{figure*}[!t]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/prelearn_vs_cautical_nontrivial.jpg}
        \subcaption{Performance comparison of \tool to \prelearn. The color indicates the number of \pr clauses learnt by \tool. We filter out all formula where neither \tool nor \prelearn learnt any \pr clauses.}
        \label{fig:cautical-vs-cadical}
    \end{subfigure}
    \hspace{0.06\textwidth}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/clauses_histogram.jpg}
        \subcaption{Histogram showing the number of \pr clauses learnt by \tool and \prelearn}
        \label{fig:cautical-vs-prelearn}
    \end{subfigure}
    \caption{Comparison of \tool and \prelearn on SAT competition benchmarks.}
    % \label{fig:solver-comparison}
\end{figure*}





% \subsection{\toolminus}

% Motivated by the fact that \tool improves mostly on formulae where it learns
% many clauses, we define a new variant \toolminus. After running the 30 second
% preprocessing step, if \toolminus does not learn at least $50$ \pr clauses, it
% will completely reset the context and run cadical. In
% \autoref{fig:toolminus-comparison}, we compare \tool to \prelearn and
% \toolminus to \prelearn on the SAT competition benchmarks.


% \begin{figure*}[!t] \centering \begin{subfigure}[t]{0.45\textwidth} \centering
%     \includegraphics[width=\textwidth]{figs/prelearn_vs_cautical.jpg}
%     \caption{Comparing \tool to \prelearn. The color indicates the number of
%     \pr clauses learnt by \tool} \label{fig:cautical-vs-cadical}
%     \end{subfigure} % \hspace{0.06\textwidth}
%     \begin{subfigure}[t]{0.45\textwidth} \centering
%     \includegraphics[width=\textwidth]{figs/prelearn_vs_cautical_minus_time.jpg}
%     \caption{Comparing \toolminus to \prelearn. The color indicates the number
%     of \pr clauses learnt by \toolminus} \label{fig:cautical-vs-prelearn}
%     \end{subfigure} \caption{Performance comparison of \tool with and
%     \toolminus with \prelearn on SAT competition benchmarks. We filter out all
%     benchmarks where both \tool and \prelearn do not learn any \pr clauses.
%     The color indicates the number of \pr clauses learnt by the \tool or
%     \toolminus.} % \label{fig:solver-comparison} \end{figure*}

% version of the graphs without filtering out clauses: prelearn_vs_cautical.jpg


\subsection{Discussion of Benchmark Families}~\label{subsec:eval-discussion}

We identify six benchmark families for which \pr clauses perform well. We choose
them based on prior work ~\cite{prelearn} and our experiments on SAT
competition benchmarks:

\begin{enumerate}
    \item \texttt{mutilated-chessboard}: A famous problem asking if one can use
    $2$-by-$1$ tiles to cover an $n$-by-$n$ chessboard with opposite corners
    removed. This is known to be difficult for
    resolution~\cite{mutilatedchessboard-exponential}, but have $O(n^3)$ \pr
    proofs~\cite{mutilatedchessboard-pr}.
    \item \texttt{perfect-matching}: A generalization of the pigeonhole
    principle and mutilated chessboard problems with various at-most-one
    constraints~\cite{bipartgen}.
    \item \texttt{pcmax-scheduling}: A problem encoding the scheduling problem
    mapping $n$ tasks with known execution times to $m$ identical
    processors~\cite{pcmax}.
    % \item
    % https://helda.helsinki.fi/server/api/core/bitstreams/3f1f286b-3def-49e9-98ba-f887b1bc250e/content
    % -> page 31
    \item \texttt{register-allocation}: A problem representing the graph
    coloring problem generated by simulating register allocation on individual
    Python functions~\cite{register-allocation}.
    \item \texttt{relativized-pigeonhole}: A generalization of the pigeonhole
    principle where we place $n+1$ pigeons in $n$ holes with $k$ nesting
    places~\cite{relativized-pigeonhole}.
    % todo: ask joseph about citation
    \item \texttt{satcoin}: An unsatisfiable variant of a bitcoin mining
    problem~\cite{satcoin}.
    \item \texttt{test=configuration}: A problem asking if there is a list of
    configurations of size $k$ that covers every pairwise combination of
    configurations of a SAT solver~\cite{test-configuration}.
\end{enumerate}

% \begin{table*}[!t]
%     \centering
%     \begin{tabularx}{\textwidth}{lXll}
%     \hline
%     Name & Description & Clause Size & Learnt Clauses \\
%     \hline
%     \texttt{mutilated-chessboard} & A famous problem asking if one can use $2$-by-$1$ tiles to cover an $n$-by-$n$ chessboard with opposite corners removed. Known to be difficult for resolution but have $O(n^3)$ \pr proofs. & $O(n^3)$ & $O(n^3)$ \\
%     \hline
%     \texttt{perfect-matching} & A generalization of the pigeonhole principle and mutilated chessboard problems with various at-most-one constraints. & - & - \\
%     \hline
%     \texttt{pcmax-scheduling} & A problem encoding the scheduling problem mapping $n$ tasks with known execution times to $m$ identical processors. & - & - \\
%     \hline
%     \texttt{register-allocation} & A problem representing the graph coloring problem generated by simulating register allocation on individual Python functions. & - & - \\
%     \hline
%     \texttt{relativized-pigeonhole} & A generalization of the pigeonhole principle where we place $n+1$ pigeons in $n$ holes with $k$ nesting places. & - & - \\
%     \hline
%     \texttt{satcoin} & An unsatisfiable variant of a bitcoin mining problem. & - & - \\
%     \hline
%     \texttt{test=configuration} & A problem asking if there is a list of configurations of size $k$ that covers every pairwise combination of configurations of a SAT solver. & - & - \\
%     \hline
%     \end{tabularx}
%     \caption{Benchmark families used in evaluation. For most benchmarks, specific clause sizes and number of learnt clauses are not provided in the literature.}
%     \label{tab:benchmarks}
%     \end{table*}

% These formulas are mostly UNSAT as these are most benefitted by \pr clause
% learning. SAT formulas are very sensitive to search heuristics, so adding a \pr
% clause can have a significant (positive or negative) effect on performance,
% regardless if a clause is actually useful.
\autoref{fig:solver-comparison-familis} compares the performance of \tool
with \cadical and \prelearn on these benchmark families. 

\tool compares favorably to \cadical on all benchmark families (except
\texttt{relativized-pigeonhole}), showing especially large speedups on
\texttt{register-allocation}, \texttt{mutilated-chessboard} and
\texttt{perfect-matching}. \prelearn overall performs better with large speedups
over \tool on \texttt{test-configuration} and \texttt{pcmax-scheduling}. \tool
performs better on smaller instances of \texttt{register-allocation} and
\texttt{mutilated-chessboard}, while \prelearn performs better on larger
instances. \tool can also solve instances of \texttt{satcoin} that
\prelearn cannot.


\begin{figure*}[!t]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figs/cadical_vs_cautical_interesting.jpg}
            \caption{Comparison with \cadical}
            \label{fig:cautical-vs-cadical}
    \end{subfigure}
        % \hspace{0.06\textwidth}
    % \hspace{0.06\textwidth} \begin{subfigure}[t]{0.3\textwidth} \centering
    % \includegraphics[width=\textwidth]{figs/prelearn_vs_cadical_interesting.jpg}
    % \caption{Comparison with \prelearn} \label{fig:cautical-vs-prelearn}
    % \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/prelearn_vs_cautical_interesting_legend.jpg}
        \caption{Comparison with \prelearn}
        \label{fig:cautical-vs-prelearn}
    \end{subfigure}

    \caption{Performance comparison of \tool with other solvers on benchmark families.}
    \label{fig:solver-comparison-familis}
\end{figure*}


% \subsection{Analysis of heuristics}~\label{subsec:eval-heuristics}



%  shows that the time limit heuristic is not useful for \tool.
%  \autoref{fig:global-sort-i} shows that sorting $i$ beforehand by frequency
%  used is not useful. \autoref{fig:global-touched} shows that the touched
%  heuristic is not useful.






% \subsection{Research Questions}~\label{subsec:eval-research-questions}

