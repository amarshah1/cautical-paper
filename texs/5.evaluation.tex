\section{Evaluation}~\label{sec:evaluation}

In this section, we empirically evaluate our techniques against other \pr clause
learning techniques. In doing so, we aim to answer the following research questions:


\begin{enumerate}
    \item Can our approach provide short \pr proofs for certain benchmark families?
    \item Is our approach less sensitive to encoding choices compared to other
    \pr learning techniques?
    % \item Can these techniques underperform or outperform SAT solvers on other certain benchmark
    % families?
\end{enumerate}


We compare the two main tools learning \pr: clauses \sadical (based on SDCL)
and \prelearn (a preprocessing technique that calls \sadical). To be consistent with our approach,
we run \prelearn with 50 iterations and for 30 seconds. We also compare to \cadical as a baseline with no \pr clause learning.

In \autoref{subsec:eval-pigeonhole}, we compare all approaches
on the pigeonhole principle. We evaluate based on time taken, proof length, and sensitivity to the encoding of the formula. 

In \autoref{subsec:eval-satcomp}, we evaluate the solvers on benchmarks from the
annual '22, '23, and '24 SAT competition's main
tracks~\cite{satcomp2022,satcomp2023,satcomp2024}.

In \autoref{subsec:eval-discussion}, we highlight certain benchmark families
that benefit from \pr clause learning. We evaluate the different approaches on these families.


Finally, we analyze the use of specific heuristic choices in \tool
by turning heuristics off individually and observing their effect (\autoref{subsec:eval-heuristics}). 

All experiments were performed in the Anvil Supercomputing Center on nodes with
128 cores and 2 GB RAM per core~\cite{anvil}. We ran 64 experiments in parallel per node
with a 5,000 second timeout, the default timeout for the SAT competition.

\subsection{Pigeonhole results}~\label{subsec:eval-pigeonhole}

\begin{figure*}[!t]
    \centering
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/pigeonhole_runtime_comparison.jpg}
        % \caption{Runtime on Pigeonhole Principle formulae}
        \label{fig:pigeonhole-runtime-comparison}
    \end{subfigure}
    \hspace{0.06\textwidth}
    \begin{subfigure}[t]{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/pigeonhole_proof_size_comparison.jpg}
        % \caption{Proof Size for Pigeonhole Principle formulae}
        \label{fig:pigeonhole-proof-size-comparison}
    \end{subfigure}
    \caption{Comparison of \tool, \cadical, \sadical, and \prelearn on pigeonhole principle benchmarks up to size $40$. The y-axis is on a cube root scale. The performance of a solver on the original benchmark is shown with a solid line. The median of 5 scranfilized queries is shown with a dashed line. If a solver times out on a query in 5000s, it is not shown.}
    \label{fig:pigeonhole-results}
\end{figure*}


Approaches based on SDCL, such as \sadical, are successful for learning $O(n^3)$ proofs for the pigeonhole
principle, but are very sensitive to the encoding of the formula. We compare the solvers on
pigeonhole principle from \ph{2} to \ph{40} and plot these results in \autoref{fig:pigeonhole-results}. As the expected best-behavior is cubic, we use a cube root scale for the y-axis.

As expected, \cadical grows exponentially, while \sadical and \tool scale cubicly in both runtime and proof size. Significantly, \tool is able to learn $3.59$-$3.64$x shorter proofs compared to \sadical. 
% on formulae larger than \ph{10}
This is because \sadical deletes clauses more frequently, as to not exclude other clauses from being learned. Frequent deletion is not necessary in \tool because of its clause shrinking technique.
\prelearn scales cubicly on small formulae, but for \ph{22} and larger, will not learn enough useful \pr clauses in the preprocessing step and times out.

% As we discuss in
% \autoref{app:pigeonhole}, \tool learns proofs of size $\approx \frac13 n^3$,
% which is expected to be shorter than known \pr proofs for the pigeonhole principle.

Additionally, we evaluate all solvers on scranfilized variations of the
pigeonhole principle. Scranfilization is a technique for generating an
equivalently satisfiable formula~\cite{scranfilize}. We use the tool
\texttt{scranfilize}~\cite{scranfilize} with the options permuting variables, permuting clauses, and flipping literals (with probability $0.5$) all turned on. We run each solver on 5 scranfilized variations for
each benchmark and take the median runtime and proof size. This is shown in \autoref{fig:pigeonhole-results} with dashed lines.

\sadical and \prelearn exhibit an exponential trend for runtime and proof size on the scranfilized benchmarks. \sadical will spend all its time in the main SDCL loop not learning enough useful clauses. \prelearn will learn some useful \pr clauses in preprocessing, but not enough to sufficiently shrink the search space for formulae larger than \ph{16}.

On the other hand, \tool almost matches its non-scranfilized performance, demonstrating that it learns useful \pr clauses regardless of the encoding.

% In conclusion, \tool is able to match \sadical's runtime for the pigeonhole principle while shorter proofs by a constant factor. Additionally, \tool is insensitive to permuting variables, permuting clauses, and flipping literals as it relies on conditional autarkies, a global property of the formula.



\subsection{SAT competition results}~\label{subsec:eval-satcomp}

\begin{figure*}[!t]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/cadical_vs_cautical_nontrivial.jpg}
        \caption{Comparing \tool to \cadical. The color indicates the number of \pr clauses learnt by \tool}
        \label{fig:cautical-vs-cadical}
    \end{subfigure}
    % \hspace{0.06\textwidth}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/cadical_vs_prelearn_nontrivial.jpg}
        \caption{Comparing \prelearn to \cadical. The color indicates the number of \pr clauses learnt by \prelearn}
        \label{fig:cautical-vs-prelearn}
    \end{subfigure}
    \caption{Performance comparison of \tool with and \prelearn with \cadical on SAT competition benchmarks. We filter out all benchmarks where the solvers do not learn any \pr clauses. The color indicates the number of \pr clauses learnt by the solver.}
    \label{fig:solver-comparison}
\end{figure*}

In \autoref{fig:solver-comparison}, we compare the performance of \tool with \cadical and \prelearn on the benchmarks from the '22,'23, and '24 SAT competition's main tracks~\cite{satcomp2022,satcomp2023,satcomp2024}. We exclude all benchmarks with more than 20M variables. \autoref{tab:solver-stats} shows the number of instances solved by each solver and the number of queries for which \prelearn and \cadical learn additional clauses, improve upon \cadical, and solve that \cadical does not solve.

PAR-2 score is a standard metric used to evaluate the performance of solvers.
It is evaluated as the sum of the runtimes of solved instances and twice the timeout of unsolved instances. On this dataset, \cadical has a PAR-score of 3521.79 seconds, \prelearn has a PAR-score of 3331.41 seconds, and \tool has a PAR-score of 3442.14 seconds.

% prelearn PAR score:  3331.406813590451
% cautical PAR score:  3442.137998163452
% cadical PAR score:  3521.7908356290172

\begin{table}[ht]
    \centering
    \sisetup{table-format=3}        % remove if you are not using siunitx
    \begin{tabular}{lrrrr}
      \toprule
      & \multicolumn{2}{c}{0--10k} & \multicolumn{2}{c}{10k--20M} \\
      \cmidrule(lr){2-3} \cmidrule(lr){4-5}
      & SAT & UNSAT & SAT & UNSAT \\
      \midrule
      Total Formulas & 55 & 91 & 332 & 312 \\
      \cadical Solved      &   54 &  73 & 319 & 303 \\
      \midrule
      \prelearn \\
      \; Total &  52 &  90 & 322 & 307 \\
      \; Learnt clauses   &  43 &  74 & 187 & 149 \\
      \; Learnt $>50$ clauses   &  24 &  52 & 108 & 81 \\
      \; Improved &  10 &  25 &  51 &  30 \\
      \; Exclusively &   1 &  17 &   6 &   6 \\
      \midrule
      \tool \\
      \; Total &  52 &  87 & 317 & 298 \\
      \; Learnt clauses     &  16 &  59  &  32 &  36 \\
      \; Learnt $>50$ clauses  &  16 &  58 &  32 &  35 \\
      \; Improved &  23 &  30 &  80 &  49 \\
      \; Exclusively &   0 &  18 &   9 &   9 \\
      \bottomrule
    \end{tabular}
    \caption{Number of solved instances.}
    \label{tab:solver-stats}
  \end{table}

%   Category                  0-10k SAT  0-10k UNSAT  10k-20M SAT  10k-20M UNSAT  20M+ SAT  20M+ UNSAT  Total
%   Total Formulas                   55           91          332            312        35          46    871
%   Cadical Solved                   54           73          319            303        35          46    830
%   Has PR Clauses                   43           74          187            149         0           3    456
%   Has Many PR Clauses              24           52          108             81         0           0    265
%   Prelearn Solved                  52           90          322            307        35          46    852
%   Prelearn Only                     1           17            6              6         0           0     30
%   Prelearn Improved                10           25           51             30         1           1    118
%   Cautical Solved                  52           87          317            298        32          29    815
%   Cautical Only                     0           18            9              9         0           0     36
%   Cautical Improved                23           30           80             49         0           8    190
%   Blocked Clauses                  16           58           32             35         0           0    141
%   Has Many Blocked Clauses          1           39            7             11         0           0     58


\subsection{\toolminus}

Motivated by the fact that \tool improves mostly on formulas where it learns many clauses, we define a new variant \toolminus. After running the 30 second preprocessing step, if \toolminus does not learn at least $50$ \pr clauses, it will completely reset the context and run cadical. In \autoref{fig:toolminus-comparison}, we compare \tool to \prelearn and \toolminus to \prelearn on the SAT competition benchmarks.


\begin{figure*}[!t]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/prelearn_vs_cautical.jpg}
        \caption{Comparing \tool to \prelearn. The color indicates the number of \pr clauses learnt by \tool}
        \label{fig:cautical-vs-cadical}
    \end{subfigure}
    % \hspace{0.06\textwidth}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/prelearn_vs_cautical_minus_time.jpg}
        \caption{Comparing \toolminus to \prelearn. The color indicates the number of \pr clauses learnt by \toolminus}
        \label{fig:cautical-vs-prelearn}
    \end{subfigure}
    \caption{Performance comparison of \tool with and \toolminus with \prelearn on SAT competition benchmarks. We filter out all benchmarks where both \tool and \prelearn do not learn any \pr clauses. The color indicates the number of \pr clauses learnt by the \tool or \toolminus.}
    % \label{fig:solver-comparison}
\end{figure*}


\subsection{Discussion of Benchmark Families}~\label{subsec:eval-discussion}

We identify six benchmark families, which \pr clauses perform well on. We choose them  based on prior work ~\cite{prelearn} and our experiments on SAT competition benchmarks:

\begin{enumerate}
    \item \texttt{mutilated-chessboard}
    \item \texttt{pcmax-scheduling}
    \item \texttt{perfect-matching}
    \item \texttt{register-allocation}
    \item \texttt{relativized\_pigeonhole}
    \item \texttt{satcoin}
    \item \texttt{test\_configuration}
\end{enumerate}

\begin{figure*}[!t]
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figs/cadical_vs_cautical_interesting.jpg}
            \caption{Comparison with \cadical}
            \label{fig:cautical-vs-cadical}
    \end{subfigure}
        % \hspace{0.06\textwidth}
    % \hspace{0.06\textwidth}
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/prelearn_vs_cadical_interesting.jpg}
        \caption{Comparison with \prelearn}
        \label{fig:cautical-vs-prelearn}
    \end{subfigure}
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/prelearn_vs_cautical_interesting_legend.jpg}
        \caption{Comparison with \prelearn}
        \label{fig:cautical-vs-prelearn}
    \end{subfigure}

    \caption{Performance comparison of \tool with other solvers}
    % \label{fig:solver-comparison}
\end{figure*}





\subsection{Analysis of heuristics}~\label{subsec:eval-heuristics}

We provide a brief analysis of the heuristics used in \tool.


\begin{figure*}[!t]
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figs/global_time_lim_heuristic_comparison.jpg}
            \caption{Time limit}
            \label{fig:global-time-comparison}
    \end{subfigure}
        % \hspace{0.06\textwidth}
    % \hspace{0.06\textwidth}
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/globalbcp_heuristic_comparison.jpg}
        \caption{BCP}
        \label{fig:globalbcp}
    \end{subfigure}
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/globaldontfilter_heuristic_comparison.jpg}
        \caption{No filter}
        \label{fig:globaldontfilter}
    \end{subfigure}

    \caption{Performance comparison of \tool with other solvers}
    % \label{fig:solver-comparison}
\end{figure*}

\begin{figure*}[!t]
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figs/globaldouble_heuristic_comparison.jpg}
            \caption{Double}
            \label{fig:cautical-vs-cadical}
    \end{subfigure}
        % \hspace{0.06\textwidth}
    % \hspace{0.06\textwidth}
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/globalisort_heuristic_comparison.jpg}
        \caption{Sort $i$ beforehand by frequency used}
        \label{fig:cautical-vs-prelearn}
    \end{subfigure}
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/globalmaxlen_heuristic_comparison.jpg}
        \caption{Max length}
        \label{fig:cautical-vs-prelearn}
    \end{subfigure}

    \caption{Performance comparison of \tool with other solvers}
    % \label{fig:solver-comparison}
\end{figure*}

\begin{figure*}[!t]
    \centering
    \begin{subfigure}[t]{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{figs/globalnoshrink_heuristic_comparison.jpg}
            \caption{No shrink}
            \label{fig:cautical-vs-cadical}
    \end{subfigure}
        % \hspace{0.06\textwidth}
    % \hspace{0.06\textwidth}
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/globalorderi_heuristic_comparison.jpg}
        \caption{Order $i$ beforehand in increasing order}
        \label{fig:cautical-vs-prelearn}
    \end{subfigure}
    \begin{subfigure}[t]{0.3\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figs/globaltouch_heuristic_comparison.jpg}
        \caption{Touched heuristic}
        \label{fig:cautical-vs-prelearn}
    \end{subfigure}

    \caption{Performance comparison of \tool with other solvers}
    % \label{fig:solver-comparison}
\end{figure*}


\subsection{Research Questions}~\label{subsec:eval-research-questions}

We answer the research questions posed at the start of this section. For
question 1, we conclude positively that \tool is able to provide short \pr
proofs for certain benchmark families. We match the best known result for The

However, it is currently unknown whether conditional autarkies can be used to
learn the shortest known \pr proofs for the mutilated
chessboard~\cite{mutilatedchessboard-pr} or Tseitin graph
formulae~\cite{sadical}. Additionally, there are benchmarks in the ??, ??, and
?? families that \prelearn solves and \tool does not.

For question 2, we can conclude positively that \tool is less sensitive to
encoding choices compared to other \pr learning techniques. We show that \tool
has $O(n^3)$ proofs for the pigeonhole principle even when the variables are
permuted, clauses are permuted, and literals are flipped. Additionally, \tool
does not consider any information about the encoding when propagating literals
(it does so randomly). In fact, we show that heuristics used to rank order
literals have an adverse effect on performance.