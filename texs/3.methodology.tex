\section{Methodology}~\label{sec:method}

\subsection{Motivating Example}~\label{sec:motivatex}

\begin{figure*}[!t]
    \centering
    \input{figs/pigeonholeclause.tex}
    \caption{Learning the clause $\overline{x}_{1, 2} \lor \overline{x}_{2, 1}$
    for \ph{4}}~\label{fig:pigeonholeclauses}
  \end{figure*}

We use the pigeonhole principle as a motivating example. The problem $\ph{n}$
asks whether we can put $n+1$ pigeons in $n$ holes such that (1)~every pigeon is
in a hole, and (2)~no hole contains more than one pigeon. This can be encoded as
a SAT problem where variable $x_{i, j}$ represents putting the $i$-th pigeon
into the $j$-th hole. Constraint (1) is encoded as $\bigvee_{1 \leq j \leq n}
x_{i, j}$ for each $1 \leq i \leq n+1$ and (2) as $\overline{x}_{i, j} \lor
\overline{x}_{k, j}$ for each $ 1 \leq i < k \leq n+1$ and $1 \leq j \leq n$.

\autoref{fig:pigeonholeclauses} provides a visualization where the rows
represent the pigeons and the columns represent the holes. The cell in row $i$
and column $j$ represents the literal $x_{i, j}$.
A $+$ in the $(i, j)$-th cell indicates that $x_{i, j}$ is set to $\top$, and a
$-$ symbol indicates $\bot$. Thus, constraint (1) asks that each row has at
least one $+$ and constraint (2) asks that each column has at most one $+$.

We achieve an $O(n^3)$ \pr proof for \ph{n}, matching the best known
result~\cite{prclauses}. In \autoref{fig:pigeonholeclauses} we learn the clause
$\overline{x}_{1, 2} \lor \overline{x}_{2, 1}$. After learning $n$ such clauses,
we learn the clause $\overline{x}_{1, 2}$, i.e. “pigeon 1 is not in hole 2.”
Since there are n+1 pigeons and n holes, we must rule out $O(n^2)$ pigeon-hole
pairs, so the proof has size $O(n^3)$. We learn these proofs with a very low
constant factor and robustness against encoding perturbations (see
\autoref{subsec:eval-pigeonhole}).

\subsection{PR Clause Learning Framework}~\label{subsec:methodology}

\begin{algorithm}\caption{Learning PR clauses}\label{alg:methodology}
    \SetAlgoNoLine \SetKwFunction{Learn}{LearnClause}
    \SetKwFunction{LCP}{LeastConditional} \SetKwFunction{Propagate}{Propagate}
    \SetKwFunction{Shrink}{Shrink} \SetKwFunction{Backtrack}{Backtrack}
    \SetKwFunction{Filter}{Filter} \SetKwFor{For}{for}{:}{}
    \SetKwFor{If}{if}{:}{} \SetKwProg{Fn}{Function}{:}{} \SetKwBlock{Begin}{}{}
    \Fn{\Learn{$\formula$, $\alpha$}}{ \For{$i \in vars(\formula)$}{
    \label{line:choose-i} \For{$j \in vars(\formula)$}{ \label{line:choose-j}
    \Propagate($i$); \\
                \Propagate($j$); \\
                $\alpha_c, \alpha_a := \LCP(\formula, \alpha)$; \\
                $C := \Shrink(\formula,\alpha_c, \alpha_a)$; \\
                \If{not  \Filter{C, $\formula$}}{ $\formula := \formula \land C$;}
                \Backtrack{}; } } }
\end{algorithm}

We present the general framework for using conditional autarkies to learn PR
clauses in \autoref{alg:methodology}. A conditional autarky is computed based on
a assignment, so the algorithm first selects a set of literals to propagate
(lines $4,5$), creating the assignment $\alpha$. We propagate two literals at a
time using nested \textbf{for} loops, and undo the propagations after each
iteration (backtracking in line $10$). In line $6$ \autoref{alg:leastcond}
makes a single pass over the formula to generate a conditional autarky, with
conditional part $\alpha_c$ and autarky part $\alpha_a$. The PR clause $C$
is generated from the conditional autarky and shrunk in line $7$, and if $C$
does not pass the usefulness heuristics it is filtered away in line $8$. Details
regarding design choices and heuristics are found in
\autoref{sec:implementation}, including a discussion of \texttt{Filter}.

In the following sections, we will describe PR clause learning and shrinking in
the context of our running example  \ph{4}. We will consider the decisions $i =
x_{1, 1}$ and $j = x_{2, 2}$ shown in \autoref{subfig:pigeonholeclause-a}, with
unit propagation shown in \autoref{subfig:pigeonholeclause-b}.

\subsection{Learning PR Clauses}~\label{subsec:learning}


As described in \autoref{subsec:autarkies}, any assignment can be split into a
conditional and a (potentially empty) autarky part, $\alpha = \alpha_c \sqcup \alpha_a$, and the
following clauses are PR: $\bigvee_{c \in \alpha_c} \overline{c} \lor a$ for
any $a \in \alpha_a$. In order to produce smaller PR clauses, we use
\autoref{alg:leastcond} from Kiesl et al. \cite{conditionalautarkies} to find
the unique smallest possible $\alpha_c$.


\begin{algorithm}
    \caption{Unique minimal $\alpha_c$ in $\alpha = \alpha_c \sqcup
    \alpha_a$}\label{alg:leastcond} \SetAlgoNoLine
    \SetKwFunction{LCP}{LeastConditional} \SetKwFor{For}{for}{:}{}
    \SetKwFor{If}{if}{:}{} \SetKwProg{Fn}{Function}{:}{} \SetKwBlock{Begin}{}{}

    \Fn{\LCP{$\formula$, $\alpha$}}{

        $\alpha_c := \emptyset$\; \For{$C \in \formula$}{ \If{$\alpha$ touches
        $C$ without satisfying $C$}{ $\alpha_c := \alpha_c \cup (\alpha \cap
        \overline{C})$\; } } \Return{$\alpha_c$, $\alpha \backslash \alpha_c$}\;
        }
\end{algorithm}

\autoref{alg:leastcond} returns $\alpha_c \sqcup \alpha_a$, which is a
conditional autarky, as every clause that $\alpha_a$ touches is satisfied by a
literal in $\alpha$.

Additionally, $\alpha_c$ is minimal: for any other conditional autarky $\alpha =
\alpha_c' \sqcup \alpha_a'$, it must be the case that $\alpha_c \subseteq
\alpha_c'$ since for each clause that is touched but not satisfied, we add to
$\alpha_c$ all literals from the assignment that touch and do not satisfy this
clause. These literals must be in $\alpha_c'$, since otherwise $\alpha_a'$ will touch a
clause that is not satisfied by $\alpha$, violating the conditional autarky
property.

Running \autoref{alg:leastcond} on the assignment from
\autoref{subfig:pigeonholeclause-b}  
gives the conditional part (red) and autarky part (orange) in
\autoref{subfig:pigeonholeclause-c}. The assigned literals from pigeons $3,4,$
and $5$ appear in $\alpha_c$ because they touch but do not satisfy the
constraint ($1$) clauses for the respective pigeons stating that every pigeon is
in a hole. However, the constraint ($1$) clauses are satisfied for pigeons $1$
and $2$, along with the touched constraint ($2$) clauses, placing the pigeons
$1$ and $2$ literals in $\alpha_a$. Intuitively, if pigeons $3,4,$ and $5$ are
not in holes $1$ or $2$, then pigeon $1$ can be placed in hole $1$ : $x_{3,1}
\lor x_{3,2} \lor x_{4,1} \lor x_{4,2} \lor x_{5,1} \lor x_{5,2} \lor x_{1,1} $
and pigeon $1$ can be kept out of hole $2$ : $x_{3,1} \lor x_{3,2} \lor x_{4,1}
\lor x_{4,2} \lor x_{5,1} \lor x_{5,2} \lor \overline{x}_{1,2} $ (likewise for
pigeon $2$ but with the holes swapped). 
The shrinking technique in the following section will help reduce the size of
these large PR clauses. 



\subsection{Shrinking PR Clauses}~\label{subsec:shrinking}

The PR clause derived from a conditional autarky can be too weak to effectively
reduce the search space.
Shrinking the PR clause, i.e., removing literals from the clause via
resolution, will strengthen its pruning power. 

At a high-level, we will generate two sets: $C_0 \subseteq \alpha_c$ and $A_0
\subseteq \alpha_a$, and show that we can learn the PR clause $\bigvee_{c \in C
\backslash C_0} \overline{c} \lor \bigvee_{a \in A_0} a$. 

First we start with $C_0$, the set of literals in the conditional part that are
inconsistent with any literal in the autarky part. Two literals $l_i$ and $l_j$
are inconsistent in a formula $\formula$ if
$\impunitclauseNoNeg{\formula}{l_i}{\overline{l}_j}$, meaning the clause
$\overline{l}_i \lor \overline{l}_j$ is RUP. Formally, $C_0 = \{c_j \in \alpha_c
\mid \exists a_i \in \alpha_a \text{ s.t. }
\impunitclause{\formula}{a_i}{c_j} \}$, with $a_i$ appearing negated
in the inconsistency check so that we can perform a resolution between the
derived binary clause  $a_i \lor c_j$ and the original PR clause $C$.

Next we generate $A_0$ which is a subset of the autarky literals that are
together inconsistent with the literals in $C_0$. So, for each $c \in C_0$ there
exists an $a \in A_0$ such that $\impunitclause{\formula}{a}{c}$. There always
exists at least one $A_0$, namely $\alpha_a$ which is used to define $C_0$, but
if a smaller $A_0$ exists it can be used to shrink the size of the PR clause. 


\begin{theorem}~\label{thm:shrunkgbcequisat} Let $\Gamma$ be a formula and
    $\alpha = \alpha_c \sqcup \alpha_a$ be a conditional autarky on $\Gamma$,
    with $\alpha_c = c_1, \dots, c_n$ and $\alpha_a = a_1, \dots, a_m$.
    Let $A_0 \subseteq \alpha_a$ be non-empty.
    Let $C_0 = \{c_j \in \alpha_c
\mid \exists a_i \in A_0 \text{ s.t. }
\impunitclause{\formula}{a_i}{c_j} \}$.
    Then formula $\formula$ is satisfiable if and only if
    $\formula \land (\bigvee_{c \in C \backslash C_0} \overline{c} \lor
    \bigvee_{a \in A_0} a)$ is satisfiable.
\end{theorem}

\begin{proof}
    \underline{$\Leftarrow$:} This is immediate


    \underline{$\Rightarrow$:} From \autoref{thm:gbcequisat}, $\formula$ is
    satisfiable implies $\formula \land (\bigvee_{c \in C} \overline{c} \lor a)$
    is satisfiable for any $a \in \alpha_a$. We will pick an $a \in A_0$. Hence,
    $\formula \land (\bigvee_{c \in C} \overline{c} \lor \bigvee_{a \in A_0} a)$
    is satisfiable since we are weakening a clause.

    By the definition of inconsistency, for each $c \in C_0$ there exists an $a
    \in A_0$ such that $\impunitclause{\formula}{a}{c}$, allowing us to derive
    the RUP clause  $a \lor c$. Each binary clause can be resolved with $
    (\bigvee_{c \in C} \overline{c} \lor \bigvee_{a \in A_0} a)$, producing
    $(\bigvee_{c \in C \backslash C_0} \overline{c} \lor \bigvee_{a \in A_0}
    a)$. 
    
\end{proof}

In fact, $\bigvee_{c \in C \backslash C_0} \overline{c} \lor \bigvee_{a \in A_0}
a$ is a PR clause with witness $\alpha_a$. 
% todo: might need to explain this more 


\noindent \textbf{Greedy Set Cover.}~\label{subsec:sym}
We can interpret the problem of finding the smallest possible $A_0$ as a set
cover problem where each literal $a \in \alpha_a$ defines the set  ${\it
SETS}(a) = \{ c \in \alpha_c \; | \; \impunitclause{\formula}{a}{c}\}$. Finding
the minimum set cover is NP-hard, so we instead approximate using a greedy
algorithm, returning a set cover at most roughly $(\ln |\alpha_c| + 1)\times$
the size of the smallest set cover~\cite{greedysetcover}. 


The greedy algorithm initializes $C_0$ as empty, and in each iteration finds the
$a \in \alpha_a$ that generates the largest set ${\it SETS}(a) \cap (\alpha_c
\backslash C_0)$, adding $a$ to $A_0$ and adding ${\it SETS}(a)$ to $C_0$. The
algorithm terminates once all sets in $\{{\it SETS}(a) \cap (\alpha_c \backslash
C_0) | a \in \alpha_a \}$ are empty. Notice that oftentimes, $C_0 \subsetneq \alpha_c$,
i.e. we do not achieve a complete cover of $\alpha_c$.


\begin{algorithm}
    \caption{Algorithm finding $A_0$}\label{alg:finda0} \SetAlgoNoLine
    \SetKwFunction{Shrink}{Shrink} \SetKwFor{For}{for}{:}{}
    \SetKwFor{If}{if}{:}{} \SetKwProg{Fn}{Function}{:}{} \Fn{\Shrink{$\formula$,
    $\alpha_a$, $\alpha_c$}}{
        ${\it SETS}$ := init \texttt{Array[len($\alpha_a$)]}\label{line:setsinits}\; \For{$i \in
        \texttt{range}(\alpha_a)$}{\label{line:fori}
        \texttt{Propagate($\overline{\alpha_a[i]}$)}\label{line:propagate}\; \texttt{implied} :=
        $\{\}$\; \For{$c \in \alpha_c$}{ \texttt{Propagate($\overline{c}$)}\;
        \If{\texttt{unsat}}{ $\texttt{implied} := \texttt{implied} \cup \{c\}$\;
        } \texttt{Backtrack(1)}\; } ${\it SETS}[i]$ := \texttt{implied}\label{line:setsi}\; }
        \Return{\texttt{GreedySetCover}(${\it SETS}$)}\; }
\end{algorithm}


In \autoref{alg:finda0}, we describe our process for calculating $A_0$. 
We initialize ${\it SETS}$ as an array (line~\ref{line:setsinits}), iterate the counter $i$ through
$\alpha_a$ (line~\ref{line:fori}), populating ${\it SETS}[i]$ with the set of literals $c \in \alpha_c$
such that $\impunitclause{\formula}{a_i}{c}$ (lines~\ref{line:propagate}-\ref{line:setsi}). Finally, we apply
\texttt{GreedySetCover} to get a small set $A_0$ that covers as much of $C$ as
possible.

Returning to the pigeonhole example, $C_0$ contains all of the literals in
$\alpha_c$ because of the binary clauses in constraint (2). The smallest
possible $A_0$ includes $\overline{x}_{2, 1}$ and $\overline{x}_{1, 2}$, whose
sets cover $\overline{x}_{3, 1}, \overline{x}_{4, 1},  \ldots, \overline{x}_{5,
1}$and  $\overline{x}_{3, 2}, \overline{x}_{4, 2},  \ldots, \overline{x}_{5, 2}$
respectively. Whereas, the sets from $x_{1, 1}$ and $x_{2, 2}$ are empty (they
are not inconsistent with the other literals). Therefore, we can learn the
clause $\overline{x}_{2, 1} \lor \overline{x}_{1, 2}$, shown in
\autoref{subfig:pigeonholeclause-d}.
